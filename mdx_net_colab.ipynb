{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucassantillifuck2fa/Colab-for-MDX_B/blob/main/mdx_net_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX9xzLur4tus"
      },
      "source": [
        "# MDX-Net Colab\n",
        "<div style=\"display:flex; align-items:center; font-size: 16px;\">\n",
        "  <img src=\"https://github.githubassets.com/pinned-octocat.svg\" alt=\"icon1\" style=\"margin-right:10px; height: 20px;\" width=\"1.5%\">\n",
        "  <span>Trained models provided in this notebook are from <a href=\"https://github.com/Anjok07\">UVR-GUI</a>.</span>\n",
        "</div>\n",
        "<div style=\"display:flex; align-items:center; font-size: 16px;\">\n",
        "  <img src=\"https://github.com/Anjok07/ultimatevocalremovergui/raw/master/gui_data/img/GUI-Icon.ico\" alt=\"icon2\" style=\"margin-right:10px; height: 20px;margin-top:10px\" width=\"1.5%\">\n",
        "  <span>OFFICIAL UVR GITHUB PAGE: <a href=\"https://github.com/Anjok07/ultimatevocalremovergui\">here</a>.</span>\n",
        "</div>\n",
        "<div style=\"display:flex; align-items:center; font-size: 16px;\">\n",
        "  <img src=\"https://avatars.githubusercontent.com/u/24620594\" alt=\"icon3\" style=\"margin-right:10px; height: 20px;\" width=\"1.5%\">\n",
        "  <span>OFFICIAL CLI Version: <a href=\"https://github.com/tsurumeso/vocal-remover\">here</a>.</span>\n",
        "</div>\n",
        "<div style=\"display:flex; align-items:center; font-size: 16px;\">\n",
        "  <img src=\"https://icons.getbootstrap.com/assets/icons/discord.svg\" alt=\"icon4\" style=\"margin-right:10px; height: 20px;\" width=\"1.5%\">\n",
        "  <span>Join our <a href=\"https://cutt.ly/0TcDjmo\">Discord server</a>!</span>\n",
        "</div>\n",
        "<sup><br>Ultimate Vocal Remover (unofficial)</sup>\n",
        "<sup><br>MDX-Net by <a href=\"https://github.com/kuielab\">kuielab</a> and adapted for Colaboratory by <a href=\"https://www.youtube.com/channel/UC0NiSV1jLMH-9E09wiDVFYw\">AudioHacker</a>.</sup>\n",
        "\n",
        "<sup><br>Your support means a lot to me. If you enjoy my work, please consider buying me a ko-fi:<br></sup>\n",
        "[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/X8X6M8FR0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Numpy Fix\n",
        "import importlib.metadata\n",
        "\n",
        "desired_version = \"1.26.0\"\n",
        "\n",
        "try:\n",
        "    installed_version = importlib.metadata.version(\"numpy\")\n",
        "    if installed_version == desired_version:\n",
        "        print(f\"NumPy {desired_version} is already installed.\")\n",
        "    else:\n",
        "        print(f\"Installing NumPy {desired_version} (current: {installed_version})...\")\n",
        "        !pip install numpy=={desired_version} --prefer-binary\n",
        "        import os\n",
        "        os._exit(00)  # Restart runtime for changes to take effect\n",
        "except importlib.metadata.PackageNotFoundError:\n",
        "    print(f\"NumPy is not installed. Installing {desired_version}...\")\n",
        "    !pip install numpy=={desired_version} --prefer-binary\n",
        "    import os\n",
        "    os._exit(00)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P1PUr3Buvtye",
        "outputId": "529b9d78-e6a3-41be-c0e9-a4b715d24822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy 1.26.0 is already installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3J69RV7G8ocb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e142fbb9-7d93-4f93-ced3-80a314b8358a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.0\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed numpy-1.26.0\n",
            "/content\n",
            "Setting up... Please wait around 1-2 minute(s).\n",
            "Looking in indexes: https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/\n",
            "Requirement already satisfied: ort-nightly-gpu in /usr/local/lib/python3.11/dist-packages (1.19.0.dev20240531001)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from ort-nightly-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ort-nightly-gpu) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from ort-nightly-gpu) (1.26.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ort-nightly-gpu) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from ort-nightly-gpu) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from ort-nightly-gpu) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->ort-nightly-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->ort-nightly-gpu) (1.3.0)\n",
            "installing requirements... done\n",
            "Please log in to your account by following the prompts in the pop-up tab.\n",
            "This step is necessary to install the files to your Google Drive.\n",
            "If you have any concerns about the safety of this notebook, you can choose not to mount your drive by unchecking the \"MountDrive\" checkbox.\n",
            "Mounted at /content/drive\n",
            "Checking for updates...\n",
            "done!\n",
            "Importing required libraries... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-2-17527edfaf06>\", line 142, in <cell line: 0>\n",
            "    import mdx\n",
            "  File \"/content/drive/MyDrive/Colab-for-MDX_B/mdx.py\", line 2, in <module>\n",
            "    import onnxruntime as ort\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onnxruntime/__init__.py\", line 23, in <module>\n",
            "    from onnxruntime.capi._pybind_state import ExecutionMode  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/_pybind_state.py\", line 32, in <module>\n",
            "    from .onnxruntime_pybind11_state import *  # noqa\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-17527edfaf06>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab-for-MDX_B/mdx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimport_capi_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mimport_capi_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnxruntime_inference_collection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceSession\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# the saved exception is raised after device version validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pybind_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExecutionMode\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pybind_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExecutionOrder\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pybind_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphOptimizationLevel\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/_pybind_state.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0monnxruntime_pybind11_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: ",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "%cd /content\n",
        "\n",
        "\n",
        "import json\n",
        "import os\n",
        "import os.path\n",
        "import gc\n",
        "import psutil\n",
        "import requests\n",
        "import subprocess\n",
        "import glob\n",
        "import time\n",
        "import logging\n",
        "import sys\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive, files, output\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "if \"first_cell_ran\" in locals():\n",
        "    print(\"You've ran this cell for this session. No need to run it again.\\nif you think something went wrong or you want to change mounting path, restart the runtime.\")\n",
        "else:\n",
        "    print('Setting up... Please wait around 1-2 minute(s).')\n",
        "\n",
        "    branch = \"https://github.com/lucassantillifuck2fa/Colab-for-MDX_B\"\n",
        "\n",
        "    model_params = \"https://raw.githubusercontent.com/TRvlvr/application_data/main/mdx_model_data/model_data_new.json\"\n",
        "    _Models = \"https://github.com/TRvlvr/model_repo/releases/download/all_public_uvr_models/\"\n",
        "    # _models = \"https://pastebin.com/raw/jBzYB8vz\"\n",
        "    _models = \"https://raw.githubusercontent.com/TRvlvr/application_data/main/filelists/download_checks.json\"\n",
        "    stem_naming = \"https://pastebin.com/raw/mpH4hRcF\"\n",
        "    arl_check_endpoint = 'https://dz.doubledouble.top/check' # param: arl?=<>\n",
        "\n",
        "    file_folder = \"Colab-for-MDX_B\"\n",
        "\n",
        "    model_ids = requests.get(_models).json()\n",
        "    model_ids = model_ids[\"mdx_download_list\"].values()\n",
        "\n",
        "    model_params = requests.get(model_params).json()\n",
        "    stem_naming = requests.get(stem_naming).json()\n",
        "\n",
        "    os.makedirs(\"tmp_models\", exist_ok=True)\n",
        "\n",
        "    # @markdown If you don't wish to mount google drive, uncheck this box.\n",
        "    MountDrive = True  # @param{type:\"boolean\"}\n",
        "    # @markdown The path for the drive to be mounted: Please be cautious when modifying this as it can cause issues if not done properly.\n",
        "    mounting_path = \"/content/drive/MyDrive\"  # @param [\"snippets:\",\"/content/drive/MyDrive\",\"/content/drive/Shareddrives/<your shared drive name>\", \"/content/drive/Shareddrives/Shared Drive\"]{allow-input: true}\n",
        "    # @markdown Force update and disregard local changes: discards all local modifications in your repository, effectively replacing all files with the versions from the original commit.\n",
        "    force_update = False  # @param{type:\"boolean\"}\n",
        "    # @markdown Auto Update (does not discard your changes)\n",
        "    auto_update = True  # @param{type:\"boolean\"}\n",
        "\n",
        "    #onnxruntime-gpu fix\n",
        "    !python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/\n",
        "\n",
        "    reqs_apt = []  # !sudo apt-get install\n",
        "    reqs_pip = [\"librosa\", \"deemix\", \"yt_dlp\"]  # pip3 install\n",
        "\n",
        "    class hide_opt:  # hide outputs\n",
        "        def __enter__(self):\n",
        "            self._original_stdout = sys.stdout\n",
        "            sys.stdout = open(os.devnull, \"w\")\n",
        "\n",
        "        def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "            sys.stdout.close()\n",
        "            sys.stdout = self._original_stdout\n",
        "\n",
        "    def get_size(bytes, suffix=\"B\"):  # read ram\n",
        "        global svmem\n",
        "        factor = 1024\n",
        "        for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "            if bytes < factor:\n",
        "                return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "            bytes /= factor\n",
        "        svmem = psutil.virtual_memory()\n",
        "\n",
        "\n",
        "    print('installing requirements...',end=' ')\n",
        "    with hide_opt():\n",
        "        for x in reqs_apt:\n",
        "            subprocess.run([\"sudo\", \"apt-get\", \"install\", x])\n",
        "        for x in reqs_pip:\n",
        "            subprocess.run([\"python3\", \"-m\", \"pip\", \"install\", x])\n",
        "    print('done')\n",
        "\n",
        "    def install_or_mount_drive():\n",
        "        print(\n",
        "            \"Please log in to your account by following the prompts in the pop-up tab.\\nThis step is necessary to install the files to your Google Drive.\\nIf you have any concerns about the safety of this notebook, you can choose not to mount your drive by unchecking the \\\"MountDrive\\\" checkbox.\"\n",
        "        )\n",
        "        drive.mount(\"/content/drive\", force_remount=True)\n",
        "        os.chdir(mounting_path)\n",
        "        # check if previous installation is done\n",
        "        if os.path.exists(os.path.join(mounting_path, file_folder)):\n",
        "            # update checking\n",
        "            os.chdir(file_folder)\n",
        "\n",
        "            if force_update:\n",
        "                print('Force updating...')\n",
        "\n",
        "                commands = [\n",
        "                    [\"git\", \"pull\"],\n",
        "                    [\"git\", \"checkout\", \"--\", \".\"],\n",
        "                ]\n",
        "\n",
        "                for cmd in commands:\n",
        "                    subprocess.run(cmd)\n",
        "\n",
        "            elif auto_update:\n",
        "                print('Checking for updates...')\n",
        "                commands = [\n",
        "                    [\"git\", \"pull\"],\n",
        "                ]\n",
        "\n",
        "                for cmd in commands:\n",
        "                    subprocess.run(cmd)\n",
        "        else:\n",
        "            subprocess.run([\"git\", \"clone\", \"https://github.com/lucassantillifuck2fa/Colab-for-MDX_B.git\"])\n",
        "            os.chdir(file_folder)\n",
        "\n",
        "    def use_uvr_without_saving():\n",
        "        global mounting_path\n",
        "        print(\"Notice: files won't be saved to personal drive.\")\n",
        "        print(f\"Downloading {file_folder}...\", end=\" \")\n",
        "        mounting_path = \"/content\"\n",
        "        with hide_opt():\n",
        "            os.chdir(mounting_path)\n",
        "            subprocess.run([\"git\", \"clone\", \"https://github.com/lucassantillifuck2fa/Colab-for-MDX_B.git\"])\n",
        "            os.chdir(file_folder)\n",
        "\n",
        "    if MountDrive:\n",
        "        install_or_mount_drive()\n",
        "    else:\n",
        "        use_uvr_without_saving()\n",
        "    print(\"done!\")\n",
        "    if not os.path.exists(\"tracks\"):\n",
        "        os.mkdir(\"tracks\")\n",
        "\n",
        "    print('Importing required libraries...',end=' ')\n",
        "\n",
        "    import os\n",
        "    import mdx\n",
        "    import librosa\n",
        "    import torch\n",
        "    import soundfile as sf\n",
        "    import numpy as np\n",
        "    import yt_dlp\n",
        "\n",
        "    from deezer import Deezer\n",
        "    from deezer import TrackFormats\n",
        "    import deemix\n",
        "    from deemix.settings import load as loadSettings\n",
        "    from deemix.downloader import Downloader\n",
        "    from deemix import generateDownloadObject\n",
        "\n",
        "    logger = logging.getLogger(\"yt_dlp\")\n",
        "    logger.setLevel(logging.ERROR)\n",
        "\n",
        "    def id_to_ptm(mkey):\n",
        "        if mkey in model_ids:\n",
        "            mpath = f\"/content/tmp_models/{mkey}\"\n",
        "            if not os.path.exists(f'/content/tmp_models/{mkey}'):\n",
        "                print('Downloading model...',end=' ')\n",
        "                subprocess.run(\n",
        "                    [\"wget\", _Models+mkey, \"-O\", mpath]\n",
        "                )\n",
        "                print(f'saved to {mpath}')\n",
        "                # get_ipython().system(f'gdown {model_id} -O /content/tmp_models/{mkey}')\n",
        "                return mpath\n",
        "            else:\n",
        "                return mpath\n",
        "        else:\n",
        "            mpath = f'models/{mkey}'\n",
        "            return mpath\n",
        "\n",
        "    def prepare_mdx(custom_param=False, dim_f=None, dim_t=None, n_fft=None, stem_name=None, compensation=None):\n",
        "        device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "        if custom_param:\n",
        "            assert not (dim_f is None or dim_t is None or n_fft is None or compensation is None), 'Custom parameter selected, but incomplete parameters are provided.'\n",
        "            mdx_model = mdx.MDX_Model(\n",
        "                device,\n",
        "                dim_f = dim_f,\n",
        "                dim_t = dim_t,\n",
        "                n_fft = n_fft,\n",
        "                stem_name=stem_name,\n",
        "                compensation=compensation\n",
        "            )\n",
        "        else:\n",
        "            model_hash = mdx.MDX.get_hash(onnx)\n",
        "            if model_hash in model_params:\n",
        "                mp = model_params.get(model_hash)\n",
        "                mdx_model = mdx.MDX_Model(\n",
        "                    device,\n",
        "                    dim_f = mp[\"mdx_dim_f_set\"],\n",
        "                    dim_t = 2**mp[\"mdx_dim_t_set\"],\n",
        "                    n_fft = mp[\"mdx_n_fft_scale_set\"],\n",
        "                    stem_name=mp[\"primary_stem\"],\n",
        "                    compensation=compensation if not custom_param and compensation is not None else mp[\"compensate\"]\n",
        "                )\n",
        "        return mdx_model\n",
        "\n",
        "    def run_mdx(onnx, mdx_model,filename,diff=False,suffix=None,diff_suffix=None, denoise=False, m_threads=1):\n",
        "        mdx_sess = mdx.MDX(onnx,mdx_model)\n",
        "        print(f\"Processing: {filename}\")\n",
        "        wave, sr = librosa.load(filename,mono=False, sr=44100)\n",
        "        # normalizing input wave gives better output\n",
        "        peak = max(np.max(wave), abs(np.min(wave)))\n",
        "        wave /= peak\n",
        "        if denoise:\n",
        "            wave_processed = -(mdx_sess.process_wave(-wave, m_threads)) + (mdx_sess.process_wave(wave, m_threads))\n",
        "            wave_processed *= 0.5\n",
        "        else:\n",
        "            wave_processed = mdx_sess.process_wave(wave, m_threads)\n",
        "        # return to previous peak\n",
        "        wave_processed *= peak\n",
        "\n",
        "        stem_name = mdx_model.stem_name if suffix is None else suffix # use suffix if provided\n",
        "        save_path = f\"{os.path.basename(os.path.splitext(filename)[0])}_{stem_name}.wav\"\n",
        "        save_path = os.path.join(\n",
        "                'separated',\n",
        "                save_path\n",
        "            )\n",
        "        sf.write(\n",
        "            save_path,\n",
        "            wave_processed.T,\n",
        "            sr\n",
        "        )\n",
        "\n",
        "        print(f'done, saved to: {save_path}')\n",
        "\n",
        "        if diff:\n",
        "            diff_stem_name = stem_naming.get(stem_name) if diff_suffix is None else diff_suffix # use suffix if provided\n",
        "            stem_name = f\"{stem_name}_diff\" if diff_stem_name is None else diff_stem_name\n",
        "            save_path = f\"{os.path.basename(os.path.splitext(filename)[0])}_{stem_name}.wav\"\n",
        "            save_path = os.path.join(\n",
        "                    'separated',\n",
        "                    save_path\n",
        "                )\n",
        "            sf.write(\n",
        "                save_path,\n",
        "                (-wave_processed.T*mdx_model.compensation)+wave.T,\n",
        "                sr\n",
        "            )\n",
        "            print(f'invert done, saved to: {save_path}')\n",
        "        del mdx_sess, wave_processed, wave\n",
        "        gc.collect()\n",
        "\n",
        "    def is_valid_url(url):\n",
        "        import re\n",
        "        regex = re.compile(\n",
        "            r'^https?://'\n",
        "            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+[A-Z]{2,6}\\.?|'\n",
        "            r'localhost|'\n",
        "            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'\n",
        "            r'(?::\\d+)?'\n",
        "            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
        "        return url is not None and regex.search(url)\n",
        "\n",
        "    def download_deezer(link, arl, fmt='FLAC'):\n",
        "        match fmt:\n",
        "            case 'FLAC':\n",
        "                bitrate = TrackFormats.FLAC\n",
        "            case 'MP3_320':\n",
        "                bitrate = TrackFormats.MP3_320\n",
        "            case 'MP3_128':\n",
        "                bitrate = TrackFormats.MP3_128\n",
        "            case _:\n",
        "                bitrate = TrackFormats.MP3_128\n",
        "\n",
        "        dz = Deezer()\n",
        "        settings = loadSettings('dz_config')\n",
        "        settings['downloadLocation'] = './tracks'\n",
        "        if not dz.login_via_arl(arl.strip()):\n",
        "            raise Exception('Error while logging in with provided ARL.')\n",
        "        downloadObject = generateDownloadObject(dz, link, bitrate)\n",
        "        print(f'Downloading {downloadObject.type}: \"{downloadObject.title}\" by {downloadObject.artist}...',end=' ',flush=True)\n",
        "        Downloader(dz, downloadObject, settings).start()\n",
        "        print(f'done.')\n",
        "\n",
        "        path_to_audio = []\n",
        "        for file in downloadObject.files:\n",
        "            path_to_audio.append(file[\"path\"])\n",
        "\n",
        "        return path_to_audio\n",
        "\n",
        "    def download_link(url):\n",
        "        ydl_opts = {\n",
        "            'format': 'bestvideo+bestaudio/best',\n",
        "            'outtmpl': '%(title)s.%(ext)s',\n",
        "            'nocheckcertificate': True,\n",
        "            'ignoreerrors': True,\n",
        "            'no_warnings': True,\n",
        "            'extractaudio': True,\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            result = ydl.extract_info(url, download=True)\n",
        "            download_path = ydl.prepare_filename(result)\n",
        "        return download_path\n",
        "\n",
        "    print('finished setting up!')\n",
        "    first_cell_ran = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hd1TzEGCiRo",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "if 'first_cell_ran' in locals():\n",
        "    os.chdir(mounting_path + '/' + file_folder + '/')\n",
        "    #parameter markdowns-----------------\n",
        "    #@markdown ### Input files\n",
        "    #@markdown Track filename: Upload your songs to the \"tracks\" folder (by default in MyDrive\\Colab-for-MDX_B\\). <br>You may provide multiple links/files by spliting them with ; <br>Or you can paste direct file path from file manager on the left.\n",
        "    filename = \"https://deezer.com/album/281108671\" #@param {type:\"string\"}\n",
        "    #@markdown onnx model (if you have your own model, upload it in models folder)\n",
        "    onnx = \"UVR-MDX-NET-Inst_HQ_5.onnx\" #@param [\"Kim_Inst.onnx\", \"Kim_Vocal_1.onnx\", \"Kim_Vocal_2.onnx\", \"kuielab_a_bass.onnx\", \"kuielab_a_drums.onnx\", \"kuielab_a_other.onnx\", \"kuielab_a_vocals.onnx\", \"kuielab_b_bass.onnx\", \"kuielab_b_drums.onnx\", \"kuielab_b_other.onnx\", \"kuielab_b_vocals.onnx\", \"Reverb_HQ_By_FoxJoy.onnx\", \"UVR-MDX-NET-Inst_1.onnx\", \"UVR-MDX-NET-Inst_2.onnx\", \"UVR-MDX-NET-Inst_3.onnx\", \"UVR-MDX-NET-Inst_HQ_1.onnx\", \"UVR-MDX-NET-Inst_HQ_2.onnx\", \"UVR-MDX-NET-Inst_Main.onnx\", \"UVR_MDXNET_1_9703.onnx\", \"UVR_MDXNET_2_9682.onnx\", \"UVR_MDXNET_3_9662.onnx\", \"UVR_MDXNET_9482.onnx\", \"UVR_MDXNET_KARA.onnx\", \"UVR_MDXNET_KARA_2.onnx\", \"UVR_MDXNET_Main.onnx\", \"UVR-MDX-NET-Inst_HQ_3.onnx\", \"UVR-MDX-NET-Inst_HQ_4.onnx\", \"UVR-MDX-NET-Inst_HQ_5.onnx\", \"UVR-MDX-NET-Voc_FT.onnx\", \"UVR-MDX-NET_Crowd_HQ_1.onnx\"]{allow-input: true}\n",
        "    #@markdown process all: processes all tracks inside tracks/ folder instead. (filename will be ignored!)\n",
        "    process_all = False  # @param{type:\"boolean\"}\n",
        "\n",
        "\n",
        "    #@markdown ### Settings\n",
        "    #@markdown invert: get difference between input and output (e.g get Instrumental out of Vocals)\n",
        "    invert = True  # @param{type:\"boolean\"}\n",
        "    #@markdown denoise: get rid of MDX noise. (This processes input track twice)\n",
        "    denoise = True  # @param{type:\"boolean\"}\n",
        "    #@markdown m_threads: like batch size, processes input wave in n threads. (beneficial for CPU)\n",
        "    m_threads = 2 #@param {type:\"slider\", min:1, max:8, step:1}\n",
        "\n",
        "    #@markdown ### Custom model parameters (Only use this if you're using new/unofficial/custom models)\n",
        "    #@markdown Use custom model parameters. (Default: unchecked, or auto)\n",
        "    use_custom_parameter = False  # @param{type:\"boolean\"}\n",
        "    #@markdown Output file suffix (usually the stem name e.g Vocals)\n",
        "    suffix = \"Vocals_custom\" #@param [\"Vocals\", \"Drums\", \"Bass\", \"Other\"]{allow-input: true}\n",
        "    suffix_invert = \"Instrumental_custom\" #@param [\"Instrumental\", \"Drumless\", \"Bassless\", \"Instruments\"]{allow-input: true}\n",
        "    #@markdown Model parameters\n",
        "    dim_f = 3072 #@param {type: \"integer\"}\n",
        "    dim_t = 256 #@param {type: \"integer\"}\n",
        "    n_fft = 6144 #@param {type: \"integer\"}\n",
        "    #@markdown use custom compensation: only if you have your own compensation value for your model. this still apply even if you don't have use_custom_parameter checked (Default: unchecked, or auto)\n",
        "    use_custom_compensation = False  # @param{type:\"boolean\"}\n",
        "    compensation = 1.000 #@param {type: \"number\"}\n",
        "\n",
        "    #@markdown ### Extras\n",
        "    #@markdown Deezer arl: paste your ARL here for deezer tracks directly!\n",
        "    arl = \"\" #@param {type:\"string\"}\n",
        "    #@markdown Track format: select track quality/format\n",
        "    track_format = \"FLAC\" #@param [\"FLAC\",\"MP3_320\",\"MP3_128\"]\n",
        "    #@markdown Print settings being used in the run\n",
        "    print_settings = True  # @param{type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "    onnx = id_to_ptm(onnx)\n",
        "    compensation = compensation if use_custom_compensation or use_custom_parameter else None\n",
        "    mdx_model = prepare_mdx(use_custom_parameter, dim_f, dim_t, n_fft, compensation=compensation)\n",
        "\n",
        "    filename_split = filename.split(';')\n",
        "\n",
        "    usable_files = []\n",
        "\n",
        "    if not process_all:\n",
        "        for fn in filename_split:\n",
        "            fn = fn.strip()\n",
        "            if is_valid_url(fn):\n",
        "                dm, ltype, lid = deemix.parseLink(fn)\n",
        "                if ltype and lid:\n",
        "                    usable_files += download_deezer(fn, arl, track_format)\n",
        "                else:\n",
        "                    print('downloading link...',end=' ')\n",
        "                    usable_files+=[download_link(fn)]\n",
        "                    print('done')\n",
        "            else:\n",
        "                usable_files.append(os.path.join('tracks',fn))\n",
        "    else:\n",
        "        for fn in glob.glob('tracks/*'):\n",
        "            usable_files.append(fn)\n",
        "    for filename in usable_files:\n",
        "        suffix_naming = suffix if use_custom_parameter else None\n",
        "        diff_suffix_naming = suffix_invert if use_custom_parameter else None\n",
        "        run_mdx(onnx, mdx_model, filename, diff=invert,suffix=suffix_naming,diff_suffix=diff_suffix_naming,denoise=denoise)\n",
        "\n",
        "    if print_settings:\n",
        "        print()\n",
        "        print('[MDX-Net_Colab settings used]')\n",
        "        print(f'Model used: {onnx}')\n",
        "        print(f'Model MD5: {mdx.MDX.get_hash(onnx)}')\n",
        "        print(f'Using de-noise: {denoise}')\n",
        "        print(f'Model parameters:')\n",
        "        print(f'    -dim_f: {mdx_model.dim_f}')\n",
        "        print(f'    -dim_t: {mdx_model.dim_t}')\n",
        "        print(f'    -n_fft: {mdx_model.n_fft}')\n",
        "        print(f'    -compensation: {mdx_model.compensation}')\n",
        "        print()\n",
        "        print('[Input file]')\n",
        "        print('filename(s): ')\n",
        "        for filename in usable_files:\n",
        "            print(f'    -{filename}')\n",
        "\n",
        "    del mdx_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMVwX5RhZSRP"
      },
      "source": [
        "# Guide\n",
        "\n",
        "This tutorial guide will walk you through the steps to use the features of this Colab notebook.\n",
        "\n",
        "## Mount Drive\n",
        "\n",
        "To mount your Google Drive, follow these steps:\n",
        "\n",
        "1. Check the box next to \"MountDrive\" if you want to mount Google Drive.\n",
        "2. Modify the \"mounting_path\" if you want to specify a different path for the drive to be mounted. **Note:** Be cautious when modifying this path as it can cause issues if not done properly.\n",
        "3. Check the box next to \"Force update and disregard local changes\" if you want to discard all local modifications in your repository and replace the files with the versions from the original commit.\n",
        "4. Check the box next to \"Auto Update\" if you want to automatically update without discarding your changes. Leave it unchecked if you want to manually update.\n",
        "\n",
        "## Input Files\n",
        "\n",
        "To upload your songs, follow these steps:\n",
        "\n",
        "1. Specify the \"track filename\" for your songs. You can provide multiple links or files by separating them with a semicolon (;).\n",
        "2. Upload your songs to the \"tracks\" folder.\n",
        "\n",
        "## ONNX Model\n",
        "\n",
        "If you have your own ONNX model, follow these steps:\n",
        "\n",
        "1. Upload your model to the \"models\" folder.\n",
        "2. Specify the \"onnx\" filename for your model.\n",
        "\n",
        "## Processing\n",
        "\n",
        "To process your tracks, follow these steps:\n",
        "\n",
        "1. If you want to process all tracks inside the \"tracks\" folder, check the box next to \"process_all\" and ignore the \"filename\" field.\n",
        "2. Specify any additional settings you want:\n",
        "   - Check the box next to \"invert\" to get the difference between input and output (e.g., get Instrumental out of Vocals).\n",
        "   - Check the box next to \"denoise\" to get rid of MDX noise. This processes the input track twice.\n",
        "   - Specify custom model parameters only if you're using new/unofficial/custom models. Use the \"use_custom_parameter\" checkbox to enable this feature.\n",
        "   - Specify the output file suffix, which is usually the stem name (e.g., Vocals). Use the \"suffix\" field to specify the suffix for normal processing and the \"suffix_invert\" field for inverted processing.\n",
        "\n",
        "## Model Parameters\n",
        "\n",
        "Specify the following custom model parameters if applicable:\n",
        "\n",
        "- \"dim_f\": The value for the `dim_f` parameter.\n",
        "- \"dim_t\": The value for the `dim_t` parameter.\n",
        "- \"n_fft\": The value for the `n_fft` parameter.\n",
        "- Check the box next to \"use_custom_compensation\" if you have your own compensation value for your model. Specify the compensation value in the \"compensation\" field.\n",
        "\n",
        "## Extras\n",
        "\n",
        "If you're working with Deezer tracks, paste your ARL (Authentication Request Library) in the \"arl\" field to directly access the tracks.\n",
        "\n",
        "Specify the \"Track format\" by selecting the desired quality/format for the track.\n",
        "\n",
        "To print the settings being used in the run, check the box next to \"print_settings\".\n",
        "\n",
        "That's it! You're now ready to use this Colab notebook. Enjoy!\n",
        "\n",
        "## For more detailed guide, proceed to this <a href=\"https://docs.google.com/document/d/17fjNvJzj8ZGSer7c7OFe_CNfUKbAxEh_OBv94ZdRG5c\">link</a>.\n",
        "credits: (discord) deton24"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}